{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo utilizando YOLOv8\n",
    "\n",
    "Este modelo é muito mais preciso, porém identifica qualquer pessoa, e não apenas sua face.\n",
    "Foi feito utilizando o modelo YOLOv8 default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# carregando o video\n",
    "input_video = cv2.VideoCapture(\"./assets/arsene.mp4\")\n",
    "\n",
    "# verificando se o video foi carregado\n",
    "if not input_video.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit(1)\n",
    "\n",
    "# carregando o modelo YOLO\n",
    "model = YOLO(\"./model.pt\")\n",
    "\n",
    "# pegando as dimensões do video para definir a dimensão do vídeo\n",
    "width  = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# criando o video de saída com arquivo, codec, fps e dimensões\n",
    "output_video = cv2.VideoWriter( './saida/YOLO.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, (width, height))\n",
    "\n",
    "while True:\n",
    "    # lendo o video frame a frame\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    # verificando se o frame foi lido\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # colocando o frame no modelo YOLO com confiança de 70%. O pŕoprio modelo já faz o plot do frame\n",
    "    # com um retangulo em volta do objeto detectado\n",
    "    result = model.predict(frame, conf=0.7)\n",
    "\n",
    "    # mostrando o video em uma janela de preview\n",
    "    cv2.imshow('Video Playback', result[0].plot())\n",
    "    \n",
    "    # salvando o frame no video de saída\n",
    "    output_video.write(result[0].plot())\n",
    "\n",
    "\n",
    "# fechando o video de entrada e saída quando o loop finaliza\n",
    "output_video.release()\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo utilizando Haar Cascades\n",
    "\n",
    "Este modelo é impreciso, porém detecta apenas faces.\n",
    "Feito utilizando o Haar Cascades para faces default do OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "input_video = cv2.VideoCapture(\"./assets/arsene.mp4\")\n",
    "\n",
    "if not input_video.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit(1)\n",
    "\n",
    "# em vez de importar o modelo, vamos importar o classificador do OpenCV\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "\n",
    "width  = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "\n",
    "output_video = cv2.VideoWriter( './saida/haar.avi',cv2.VideoWriter_fourcc(*'DIVX'), 24, (width, height))\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = input_video.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # convertendo o frame para escala de cinza para podermos usar o classificador\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detectando as faces no frame. O Haar não plota o retângulo, então precisamos fazer isso manualmente\n",
    "    # pelas coordenadas retornadas\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 10)\n",
    "\n",
    "    # desenhando um retângulo em volta de cada face detectada\n",
    "    for (x,y,w,h) in faces:\n",
    "        frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),4)\n",
    "\n",
    "    cv2.imshow('Video Playback', frame)\n",
    "    \n",
    "    output_video.write(frame)\n",
    "\n",
    "    \n",
    "output_video.release()\n",
    "input_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
